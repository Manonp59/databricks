{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44ca8a84-8a11-4f96-811b-4bcf011ffe9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Créer le dossier tmp dans /dbfs\n",
    "os.makedirs('/dbfs/tmp', exist_ok=True)\n",
    "\n",
    "links = [\n",
    "    (\"2016\",\"https://www.data.gouv.fr/api/1/datasets/r/0c83108b-f87b-470d-8980-6207ac93f4eb\"),\n",
    "    (\"2017\",\"https://www.data.gouv.fr/api/1/datasets/r/5785427b-3167-49fa-a581-aef835f0fb04\"),\n",
    "    (\"2018\",\"https://www.data.gouv.fr/api/1/datasets/r/e7514726-19ec-47dc-bcc3-a59c9bfa5f7f\"), \n",
    "    (\"2019\", \"https://www.data.gouv.fr/api/1/datasets/r/a6f74cfd-b4f7-44fb-8772-7884775b35e1\"),\n",
    "    (\"2020\", \"https://www.data.gouv.fr/api/1/datasets/r/1913d0d6-d650-409d-a19e-b7c7f09e09a0\"),\n",
    "    (\"2021\", \"https://www.data.gouv.fr/api/1/datasets/r/3c5ebbd9-f6b5-4837-a194-12bfeda7f38e\"),\n",
    "    (\"2022\", \"https://www.data.gouv.fr/api/1/datasets/r/77d3151a-739e-4aab-8c34-7a15d7fea55d\"),\n",
    "    (\"2023\", \"https://www.data.gouv.fr/api/1/datasets/r/96452cf0-329a-4908-8adb-8f061adcca4c\"),\n",
    "    (\"2024\", \"https://www.data.gouv.fr/api/1/datasets/r/c0350599-a041-4724-9942-ad4c2ba9a7b3\"),\n",
    "    (\"2025\", \"https://www.data.gouv.fr/api/1/datasets/r/6994a9f1-3f4b-4e15-a4dc-0e358a6aac13\")]\n",
    "\n",
    "# Parcours pour chaque année\n",
    "for year, link in links:\n",
    "    url = link\n",
    "    destination_path = f\"/dbfs/tmp/dis-{year}-dept.zip\"\n",
    "    print(f\"Téléchargement de {url} dans {destination_path}\")\n",
    "    \n",
    "    # Exécuter le téléchargement\n",
    "    os.system(f\"wget {url} -O {destination_path}\")\n",
    "    extract_path = f\"/dbfs/tmp/extracted_files/{year}\"\n",
    "    os.makedirs(extract_path, exist_ok=True)\n",
    "    \n",
    "    print(f\"Extraction de {destination_path} dans {extract_path}\")\n",
    "    with zipfile.ZipFile(destination_path, 'r') as zip_ref:\n",
    "        # Extraction uniquement des fichiers .txt\n",
    "        for file_info in zip_ref.infolist():\n",
    "            if file_info.filename.endswith('.txt'):\n",
    "                zip_ref.extract(file_info, extract_path)\n",
    "                print(f\"Fichier extrait : {file_info.filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23f98449-c819-4223-90e5-f5a399d465fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "# Configurations\n",
    "scope_name = \"my-scope\"\n",
    "key_name = \"adls-key\"\n",
    "account_url = \"https://datalakequaliteeau.blob.core.windows.net/\"\n",
    "container_name = \"source\"\n",
    "local_base_path = \"/dbfs/tmp/extracted_files\"\n",
    "\n",
    "# Récupérer la clé d'accès\n",
    "credential = dbutils.secrets.get(scope=scope_name, key=key_name)\n",
    "\n",
    "# Créer le client de stockage\n",
    "blob_service_client = BlobServiceClient(account_url=account_url, credential=credential)\n",
    "\n",
    "# Parcourir toutes les années et tous les fichiers\n",
    "for year in range(2016, 2026):\n",
    "    year_path = os.path.join(local_base_path, str(year))\n",
    "    if os.path.exists(year_path):\n",
    "        for root, dirs, files in os.walk(year_path):\n",
    "            for filename in files:\n",
    "                file_path = os.path.join(root, filename)\n",
    "\n",
    "                # Déterminer le dossier de destination selon le nom du fichier\n",
    "                if \"PLV\" in filename.upper():\n",
    "                    folder_dest = \"PLV\"\n",
    "                elif \"COM\" in filename.upper():\n",
    "                    folder_dest = \"COM\"\n",
    "                elif \"RESULT\" in filename.upper():\n",
    "                    folder_dest = \"RESULT\"\n",
    "                else:\n",
    "                    folder_dest = \"AUTRES\"  # Optionnel, si vous voulez gérer autrement\n",
    "\n",
    "                # Créer le chemin blob\n",
    "                blob_name = f\"{folder_dest}/{filename}\"\n",
    "\n",
    "                # Créer le blob client\n",
    "                container_client = blob_service_client.get_container_client(container_name)\n",
    "                blob_client = container_client.get_blob_client(blob=blob_name)\n",
    "\n",
    "                # Upload\n",
    "                with open(file_path, \"rb\") as data:\n",
    "                    blob_client.upload_blob(data, overwrite=True)\n",
    "                print(f\"Fichier {filename} uploadé dans {blob_name}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "01_SOURCE_TO_LANDZONE",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
