{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c89093a4-c288-4c15-b4bf-572f83a18d2a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install great_expectations\n",
    "\n",
    "import great_expectations as gx\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "import glob, os\n",
    "\n",
    "context = gx.get_context(context_root_dir=\"/dbfs/great_expectations\")\n",
    "\n",
    "df = spark.table(\"GOLD.gold_sample_summary\")\n",
    "df = df.toPandas()\n",
    "\n",
    "# Create Data Context.\n",
    "context = gx.get_context()\n",
    "\n",
    "# Connect to data.\n",
    "# Create Data Source, Data Asset, Batch Definition, and Batch.\n",
    "data_source = context.data_sources.add_pandas(\"pandas\")\n",
    "data_asset = data_source.add_dataframe_asset(name=\"pd dataframe asset\")\n",
    "\n",
    "batch_definition = data_asset.add_batch_definition_whole_dataframe(\"batch definition\")\n",
    "batch = batch_definition.get_batch(batch_parameters={\"dataframe\": df})\n",
    "\n",
    "suite = gx.ExpectationSuite(name=\"gold_sample_summary_suite\")\n",
    "suite = context.suites.add(suite)\n",
    "\n",
    "suite.add_expectation(\n",
    "    gx.expectations.ExpectColumnValuesToBeBetween(column=\"year\", min_value=2016, max_value=2025, severity=\"warning\")\n",
    ")\n",
    "suite.add_expectation(\n",
    "    gx.expectations.ExpectColumnValuesToNotBeNull(column=\"inseecommuneprinc\")\n",
    ")\n",
    "suite.add_expectation(\n",
    "    gx.expectations.ExpectColumnValuesToMatchRegex(column=\"inseecommuneprinc\", regex=r\"^(?:\\d{2}|2A|2B)\\d{3}$\")\n",
    ")\n",
    "\n",
    "suite.add_expectation(\n",
    "    gx.expectations.ExpectColumnValuesToNotBeNull(column=\"nomcommuneprinc\")\n",
    ")\n",
    "suite.add_expectation(\n",
    "    gx.expectations.ExpectColumnValuesToNotMatchRegex(column=\"nomcommuneprinc\", regex=r\"^\\s*$\")\n",
    ")\n",
    "suite.add_expectation(\n",
    "    gx.expectations.ExpectColumnValuesToBeBetween(column=\"year\", min_value=2016, max_value=2025)\n",
    ")\n",
    "suite.add_expectation(\n",
    "    gx.expectations.ExpectColumnValuesToNotBeNull(column=\"total_samples\")\n",
    ")\n",
    "suite.add_expectation(\n",
    "    gx.expectations.ExpectColumnValuesToBeBetween(column=\"compliance_rate\", min_value=0.0, max_value=1.0)\n",
    ")\n",
    "\n",
    "validation_result = batch.validate(suite)\n",
    "print(validation_result)\n",
    "def print_ge_validation_report(validation_result):\n",
    "    print(\"=== RAPPORT DE VALIDATION GREAT EXPECTATIONS ===\")\n",
    "    stats = validation_result[\"statistics\"]\n",
    "    print(f\"Statut général : {'SUCCESS' if validation_result['success'] else 'FAILED'}\")\n",
    "    print(f\"Taux de réussite : {stats['success_percent']:.1f}%\")\n",
    "    print(f\"Nombre d'expectations évaluées : {stats['evaluated_expectations']}\")\n",
    "    print(f\"Réussies  : {stats['successful_expectations']}\")\n",
    "    print(f\"Ratées    : {stats['unsuccessful_expectations']}\")\n",
    "    print()\n",
    "\n",
    "    for i, res in enumerate(validation_result[\"results\"], 1):\n",
    "        cfg = res[\"expectation_config\"]\n",
    "        exp_type = cfg[\"type\"]\n",
    "        col = cfg[\"kwargs\"].get(\"column\", \"(Any)\")\n",
    "        min_v = cfg[\"kwargs\"].get(\"min_value\")\n",
    "        max_v = cfg[\"kwargs\"].get(\"max_value\")\n",
    "        severity = cfg.get(\"severity\", \"info\")\n",
    "        status = \"SUCCESS\" if res[\"success\"] else \"FAILED\"\n",
    "        result = res[\"result\"]\n",
    "        unexpected = result.get(\"unexpected_count\", 0)\n",
    "        unexpected_pct = result.get(\"unexpected_percent\", 0.0)\n",
    "        missing = result.get(\"missing_count\", 0)\n",
    "        n_total = result.get(\"element_count\", \"n/a\")\n",
    "        \n",
    "        print(f\"[{i}] {exp_type} sur colonne '{col}' (min={min_v}, max={max_v})\")\n",
    "        print(f\"    Statut         : {status} (severity : {severity})\")\n",
    "        print(f\"    Nb valeurs     : {n_total}\")\n",
    "        print(f\"    Inattendues    : {unexpected} ({unexpected_pct:.2f}%)\")\n",
    "        print(f\"    Valeurs manquantes : {missing}\")\n",
    "        # Afficher exemples inattendus s'il y en a\n",
    "        partial_unx = result.get('partial_unexpected_list', [])\n",
    "        if partial_unx:\n",
    "            print(f\"    Exemples de valeurs inattendues : {partial_unx}\")\n",
    "        print()\n",
    "    print(\"=== FIN RAPPORT ===\")\n",
    "\n",
    "# Utilisation :\n",
    "print_ge_validation_report(validation_result)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "05_DATA_VALIDATION",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
